"""
Medical Workflow Scheduling Simulator - é«˜åº¦ä¼˜åŒ–ç‰ˆæœ¬
åŒ»ç–—å·¥ä½œæµè°ƒåº¦ä»¿çœŸå™¨ - ä¸“ä¸ºç¨³å®šåŒ–HD-DDPGè®¾è®¡

ğŸ¯ ä¸»è¦ä¼˜åŒ–ï¼š
- ä¸ç¨³å®šåŒ–ç®—æ³•å®Œç¾é›†æˆ
- çŠ¶æ€ç®¡ç†ç¨³å®šåŒ–
- å¥–åŠ±æœºåˆ¶ä¸€è‡´æ€§
- å®æ—¶ç¨³å®šæ€§ç›‘æ§
"""

import numpy as np
import time
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import pandas as pd
from collections import deque
import json

from .fog_cloud_env import FogCloudEnvironment
from .workflow_generator import MedicalWorkflowGenerator, MedicalTask
from ..algorithms.hd_ddpg import HDDDPG
from ..utils.metrics import SchedulingMetrics


class StabilizedMedicalSchedulingSimulator:
    """
    ç¨³å®šåŒ–åŒ»ç–—å·¥ä½œæµè°ƒåº¦ä»¿çœŸå™¨
    ğŸ¯ ä¸“ä¸ºç¨³å®šåŒ–HD-DDPGç®—æ³•è®¾è®¡çš„å¢å¼ºä»¿çœŸç¯å¢ƒ
    """

    def __init__(self, config: Dict = None):
        # ğŸ¯ ä¼˜åŒ–çš„é»˜è®¤é…ç½®
        self.config = {
            'simulation_episodes': 1000,
            'workflows_per_episode': 8,  # å‡å°‘ä»¥æå‡ç¨³å®šæ€§
            'min_workflow_size': 6,
            'max_workflow_size': 12,
            'workflow_types': ['radiology', 'pathology', 'general'],
            'failure_rate': 0.008,  # é™ä½æ•…éšœç‡
            'save_interval': 100,
            'evaluation_interval': 25,  # æ›´é¢‘ç¹çš„è¯„ä¼°
            # ğŸ¯ æ–°å¢ç¨³å®šæ€§é…ç½®
            'stability_monitoring': True,
            'state_smoothing': True,
            'reward_normalization': True,
            'performance_tracking_window': 50,
            'convergence_threshold': 0.05,
            'makespan_target': 1.5,  # ç›®æ ‡makespan
        }

        if config:
            self.config.update(config)

        print("ğŸ”§ åˆå§‹åŒ–StabilizedMedicalSchedulingSimulator...")

        # åˆå§‹åŒ–ç»„ä»¶
        try:
            self.environment = FogCloudEnvironment()
            print("âœ… FogCloudç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

            self.workflow_generator = MedicalWorkflowGenerator()
            print("âœ… å·¥ä½œæµç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")

            # ğŸ¯ ä½¿ç”¨ä¼˜åŒ–çš„HD-DDPGé…ç½®
            optimized_config = {
                'makespan_weight': 0.7,
                'stability_weight': 0.15,
                'action_smoothing': True,
                'verbose': True
            }
            self.hd_ddpg = HDDDPG(optimized_config)
            print("âœ… ä¼˜åŒ–HD-DDPGç®—æ³•åˆå§‹åŒ–å®Œæˆ")

            self.metrics = SchedulingMetrics()
            print("âœ… æŒ‡æ ‡è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

        # ğŸ¯ ç¨³å®šæ€§ç›‘æ§ç³»ç»Ÿ
        self.stability_monitor = {
            'makespan_history': deque(maxlen=100),
            'reward_variance': deque(maxlen=50),
            'convergence_metrics': deque(maxlen=30),
            'system_health': deque(maxlen=20),
            'performance_trends': {}
        }

        # ä»¿çœŸçŠ¶æ€
        self.simulation_results = []
        self.baseline_results = []
        self.current_episode = 0
        self.best_performance = {
            'makespan': float('inf'),
            'reward': float('-inf'),
            'episode': 0
        }

        # ğŸ¯ çŠ¶æ€å¹³æ»‘ç¼“å†²åŒº
        if self.config['state_smoothing']:
            self.state_buffer = deque(maxlen=5)

        print("âœ… StabilizedMedicalSchedulingSimulatoråˆå§‹åŒ–å®Œæˆ")

    def run_simulation(self, episodes: int = None) -> Dict:
        """
        ğŸ¯ è¿è¡Œç¨³å®šåŒ–ä»¿çœŸå®éªŒ
        """
        if episodes is None:
            episodes = self.config['simulation_episodes']

        print(f"ğŸš€ å¼€å§‹ç¨³å®šåŒ–HD-DDPGåŒ»ç–—è°ƒåº¦ä»¿çœŸ - {episodes} episodes")
        simulation_start_time = time.time()

        # ğŸ¯ é¢„çƒ­é˜¶æ®µ
        print("ğŸ”¥ æ‰§è¡Œé¢„çƒ­é˜¶æ®µ...")
        self._warmup_phase()

        for episode in range(episodes):
            episode_start_time = time.time()

            try:
                # ğŸ¯ ç¨³å®šåŒ–çš„episodeæ‰§è¡Œ
                episode_result = self._run_stabilized_episode(episode)

                # ğŸ¯ æ›´æ–°ç¨³å®šæ€§ç›‘æ§
                self._update_stability_monitoring(episode_result)

                # ğŸ¯ è®°å½•ç»“æœ
                self.simulation_results.append(episode_result)

                # ğŸ¯ æ›´æ–°æœ€ä½³æ€§èƒ½
                self._update_best_performance(episode_result, episode)

                # ğŸ¯ å®šæœŸè¯„ä¼°å’Œä¿å­˜
                if (episode + 1) % self.config['evaluation_interval'] == 0:
                    self._enhanced_performance_evaluation(episode + 1)

                if (episode + 1) % self.config['save_interval'] == 0:
                    self._save_enhanced_checkpoint(episode + 1)

                # ğŸ¯ æ™ºèƒ½è¿›åº¦æŠ¥å‘Š
                if (episode + 1) % 25 == 0:
                    self._print_enhanced_progress(episode + 1, episodes)

                # ğŸ¯ æ—©æœŸåœæ­¢æ£€æŸ¥
                if self._check_convergence(episode):
                    print(f"ğŸ‰ åœ¨episode {episode + 1}æ£€æµ‹åˆ°æ”¶æ•›ï¼Œæå‰åœæ­¢")
                    break

            except Exception as e:
                print(f"âš ï¸ Episode {episode + 1}æ‰§è¡Œé”™è¯¯: {e}")
                # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
                episode_result = self._create_error_result(episode, str(e))
                self.simulation_results.append(episode_result)

        simulation_duration = time.time() - simulation_start_time

        # ğŸ¯ ç”Ÿæˆå¢å¼ºçš„æœ€ç»ˆæŠ¥å‘Š
        final_report = self._generate_enhanced_final_report(simulation_duration)

        print(f"âœ… ä»¿çœŸå®Œæˆï¼Œæ€»è€—æ—¶: {simulation_duration:.2f}ç§’")
        print(f"ğŸ† æœ€ä½³Makespan: {self.best_performance['makespan']:.3f} (Episode {self.best_performance['episode']})")

        return final_report

    def _warmup_phase(self):
        """ğŸ¯ é¢„çƒ­é˜¶æ®µ - ç¨³å®šåŒ–ç³»ç»Ÿåˆå§‹çŠ¶æ€"""
        print("  æ‰§è¡Œç³»ç»Ÿé¢„çƒ­...")

        # ç”Ÿæˆé¢„çƒ­å·¥ä½œæµ
        warmup_workflows = self._generate_episode_workflows(count=3)

        # é¢„çƒ­ç¯å¢ƒå’Œç®—æ³•
        for i, workflow in enumerate(warmup_workflows):
            self.environment.reset()
            try:
                _ = self.hd_ddpg.schedule_workflow(workflow, self.environment)
                print(f"  é¢„çƒ­å·¥ä½œæµ {i+1}/3 å®Œæˆ")
            except Exception as e:
                print(f"  é¢„çƒ­å·¥ä½œæµ {i+1}å¤±è´¥: {e}")

        print("âœ… é¢„çƒ­å®Œæˆ")

    def _run_stabilized_episode(self, episode: int) -> Dict:
        """ğŸ¯ è¿è¡Œç¨³å®šåŒ–çš„episode"""
        episode_start_time = time.time()

        # ç”Ÿæˆå½“å‰episodeçš„å·¥ä½œæµ
        workflows = self._generate_episode_workflows()

        # ğŸ¯ ç¨³å®šåŒ–çš„æ•…éšœæ¨¡æ‹Ÿ
        if np.random.random() < self.config['failure_rate']:
            self._simulate_stabilized_failure()

        # ğŸ¯ è·å–ç¨³å®šåŒ–çš„ç³»ç»ŸçŠ¶æ€
        initial_system_state = self._get_stabilized_system_state()

        # HD-DDPGè®­ç»ƒepisode
        hd_ddpg_result = self.hd_ddpg.train_episode(workflows, self.environment)

        # ğŸ¯ è®¡ç®—ç¨³å®šæ€§æŒ‡æ ‡
        stability_metrics = self._calculate_episode_stability(hd_ddpg_result)

        # ğŸ¯ å¢å¼ºçš„episodeç»“æœ
        episode_result = {
            'episode': episode + 1,
            'workflows_count': len(workflows),
            'hd_ddpg_result': hd_ddpg_result,
            'stability_metrics': stability_metrics,
            'episode_duration': time.time() - episode_start_time,
            'initial_system_state': initial_system_state.tolist(),
            'system_health': self._assess_system_health(),
            'convergence_indicator': self._calculate_convergence_indicator()
        }

        return episode_result

    def _get_stabilized_system_state(self) -> np.ndarray:
        """ğŸ¯ è·å–ç¨³å®šåŒ–çš„ç³»ç»ŸçŠ¶æ€"""
        try:
            current_state = self.environment.get_system_state()

            if self.config['state_smoothing'] and len(self.state_buffer) > 0:
                # çŠ¶æ€å¹³æ»‘åŒ–
                self.state_buffer.append(current_state)

                # è®¡ç®—åŠ æƒå¹³å‡
                weights = np.exp(-np.arange(len(self.state_buffer)) * 0.3)
                weights = weights / np.sum(weights)

                state_array = np.array(list(self.state_buffer))
                smoothed_state = np.average(state_array, axis=0, weights=weights)

                return smoothed_state
            else:
                if self.config['state_smoothing']:
                    self.state_buffer.append(current_state)
                return current_state

        except Exception as e:
            print(f"âš ï¸ è·å–ç¨³å®šåŒ–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤çŠ¶æ€
            return np.random.random(15)

    def _simulate_stabilized_failure(self):
        """ğŸ¯ ç¨³å®šåŒ–çš„æ•…éšœæ¨¡æ‹Ÿ"""
        try:
            # æ›´æ¸©å’Œçš„æ•…éšœæ¨¡æ‹Ÿï¼Œé¿å…ç³»ç»Ÿå‰§çƒˆæ³¢åŠ¨
            failure_types = ['node_slow', 'network_delay', 'minor_outage']
            failure_type = np.random.choice(failure_types)

            if hasattr(self.environment, 'simulate_mild_failure'):
                self.environment.simulate_mild_failure(failure_type)
            else:
                self.environment.simulate_failure()

        except Exception as e:
            print(f"âš ï¸ æ•…éšœæ¨¡æ‹Ÿé”™è¯¯: {e}")

    def _calculate_episode_stability(self, hd_ddpg_result: Dict) -> Dict:
        """ğŸ¯ è®¡ç®—episodeç¨³å®šæ€§æŒ‡æ ‡"""
        try:
            makespan = hd_ddpg_result.get('avg_makespan', float('inf'))
            reward = hd_ddpg_result.get('total_reward', 0)

            # æ›´æ–°å†å²è®°å½•
            self.stability_monitor['makespan_history'].append(makespan)

            stability_metrics = {
                'makespan_stability': 0,
                'reward_consistency': 0,
                'performance_trend': 0,
                'target_achievement': 0
            }

            # Makespanç¨³å®šæ€§
            if len(self.stability_monitor['makespan_history']) >= 5:
                recent_makespans = list(self.stability_monitor['makespan_history'])[-5:]
                makespan_variance = np.var(recent_makespans)
                makespan_mean = np.mean(recent_makespans)

                if makespan_mean > 0:
                    stability_metrics['makespan_stability'] = 1.0 / (1.0 + makespan_variance / makespan_mean)

            # å¥–åŠ±ä¸€è‡´æ€§
            if hasattr(hd_ddpg_result, 'reward_variance'):
                reward_var = hd_ddpg_result.get('reward_variance', 0)
                stability_metrics['reward_consistency'] = 1.0 / (1.0 + reward_var)

            # æ€§èƒ½è¶‹åŠ¿
            if len(self.stability_monitor['makespan_history']) >= 10:
                recent_performance = list(self.stability_monitor['makespan_history'])[-10:]
                trend_slope = np.polyfit(range(len(recent_performance)), recent_performance, 1)[0]
                stability_metrics['performance_trend'] = max(0, -trend_slope)  # è´Ÿæ–œç‡æ˜¯å¥½çš„

            # ç›®æ ‡è¾¾æˆåº¦
            target_makespan = self.config.get('makespan_target', 1.5)
            if makespan < float('inf'):
                stability_metrics['target_achievement'] = max(0, 1.0 - (makespan - target_makespan) / target_makespan)

            return stability_metrics

        except Exception as e:
            print(f"âš ï¸ ç¨³å®šæ€§æŒ‡æ ‡è®¡ç®—é”™è¯¯: {e}")
            return {
                'makespan_stability': 0,
                'reward_consistency': 0,
                'performance_trend': 0,
                'target_achievement': 0
            }

    def _assess_system_health(self) -> float:
        """ğŸ¯ è¯„ä¼°ç³»ç»Ÿå¥åº·åº¦"""
        try:
            health_score = 1.0

            # æ£€æŸ¥ç¯å¢ƒçŠ¶æ€
            if hasattr(self.environment, 'get_system_health'):
                env_health = self.environment.get_system_health()
                health_score *= env_health

            # æ£€æŸ¥ç®—æ³•çŠ¶æ€
            if hasattr(self.hd_ddpg, 'get_optimization_status'):
                algo_status = self.hd_ddpg.get_optimization_status()
                if algo_status.get('optimization_progress', {}).get('stable', False):
                    health_score *= 1.1

            # æ£€æŸ¥ç¨³å®šæ€§å†å²
            if len(self.stability_monitor['makespan_history']) >= 10:
                recent_variance = np.var(list(self.stability_monitor['makespan_history'])[-10:])
                if recent_variance < 0.1:
                    health_score *= 1.05

            return min(1.0, health_score)

        except Exception as e:
            print(f"âš ï¸ ç³»ç»Ÿå¥åº·è¯„ä¼°é”™è¯¯: {e}")
            return 0.5

    def _calculate_convergence_indicator(self) -> float:
        """ğŸ¯ è®¡ç®—æ”¶æ•›æŒ‡æ ‡"""
        try:
            if len(self.stability_monitor['makespan_history']) < 20:
                return 0.0

            recent_makespans = list(self.stability_monitor['makespan_history'])[-20:]

            # è®¡ç®—å˜å¼‚ç³»æ•°
            mean_makespan = np.mean(recent_makespans)
            std_makespan = np.std(recent_makespans)

            if mean_makespan > 0:
                cv = std_makespan / mean_makespan
                convergence_score = max(0, 1.0 - cv * 10)  # CVè¶Šå°ï¼Œæ”¶æ•›æ€§è¶Šå¥½
                return convergence_score

            return 0.0

        except Exception as e:
            print(f"âš ï¸ æ”¶æ•›æŒ‡æ ‡è®¡ç®—é”™è¯¯: {e}")
            return 0.0

    def _update_stability_monitoring(self, episode_result: Dict):
        """ğŸ¯ æ›´æ–°ç¨³å®šæ€§ç›‘æ§"""
        try:
            # æ›´æ–°ç¨³å®šæ€§æŒ‡æ ‡
            stability_metrics = episode_result.get('stability_metrics', {})
            system_health = episode_result.get('system_health', 0)

            self.stability_monitor['system_health'].append(system_health)

            # æ›´æ–°æ”¶æ•›æŒ‡æ ‡
            convergence_indicator = episode_result.get('convergence_indicator', 0)
            self.stability_monitor['convergence_metrics'].append(convergence_indicator)

            # è®¡ç®—å¥–åŠ±æ–¹å·®
            hd_ddpg_result = episode_result.get('hd_ddpg_result', {})
            reward_variance = hd_ddpg_result.get('reward_variance', 0)
            self.stability_monitor['reward_variance'].append(reward_variance)

        except Exception as e:
            print(f"âš ï¸ ç¨³å®šæ€§ç›‘æ§æ›´æ–°é”™è¯¯: {e}")

    def _update_best_performance(self, episode_result: Dict, episode: int):
        """ğŸ¯ æ›´æ–°æœ€ä½³æ€§èƒ½è®°å½•"""
        try:
            hd_ddpg_result = episode_result.get('hd_ddpg_result', {})
            makespan = hd_ddpg_result.get('avg_makespan', float('inf'))
            reward = hd_ddpg_result.get('total_reward', float('-inf'))

            # æ›´æ–°æœ€ä½³makespan
            if makespan < self.best_performance['makespan'] and makespan != float('inf'):
                self.best_performance['makespan'] = makespan
                self.best_performance['episode'] = episode + 1
                print(f"ğŸ† æ–°çš„æœ€ä½³Makespan: {makespan:.3f} (Episode {episode + 1})")

            # æ›´æ–°æœ€ä½³å¥–åŠ±
            if reward > self.best_performance['reward']:
                self.best_performance['reward'] = reward

        except Exception as e:
            print(f"âš ï¸ æœ€ä½³æ€§èƒ½æ›´æ–°é”™è¯¯: {e}")

    def _check_convergence(self, episode: int) -> bool:
        """ğŸ¯ æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        try:
            if episode < 100:  # è‡³å°‘è®­ç»ƒ100è½®
                return False

            if len(self.stability_monitor['convergence_metrics']) < 10:
                return False

            # æ£€æŸ¥æ”¶æ•›æŒ‡æ ‡
            recent_convergence = list(self.stability_monitor['convergence_metrics'])[-10:]
            avg_convergence = np.mean(recent_convergence)

            convergence_threshold = self.config.get('convergence_threshold', 0.05)

            # æ£€æŸ¥makespanç¨³å®šæ€§
            if len(self.stability_monitor['makespan_history']) >= 20:
                recent_makespans = list(self.stability_monitor['makespan_history'])[-20:]
                makespan_std = np.std(recent_makespans)
                makespan_mean = np.mean(recent_makespans)

                if makespan_mean > 0:
                    cv = makespan_std / makespan_mean
                    return cv < convergence_threshold and avg_convergence > 0.8

            return False

        except Exception as e:
            print(f"âš ï¸ æ”¶æ•›æ£€æŸ¥é”™è¯¯: {e}")
            return False

    def _enhanced_performance_evaluation(self, episode: int):
        """ğŸ¯ å¢å¼ºçš„æ€§èƒ½è¯„ä¼°"""
        if not self.simulation_results:
            return

        print(f"\nğŸ“Š Episode {episode} - å¢å¼ºæ€§èƒ½è¯„ä¼°:")

        try:
            # è·å–æœ€è¿‘çš„ç»“æœ
            window_size = min(self.config['performance_tracking_window'], len(self.simulation_results))
            recent_results = self.simulation_results[-window_size:]

            # è®¡ç®—å…³é”®æŒ‡æ ‡
            avg_reward = np.mean([r['hd_ddpg_result']['total_reward'] for r in recent_results])
            avg_makespan = np.mean([r['hd_ddpg_result']['avg_makespan'] for r in recent_results
                                  if r['hd_ddpg_result']['avg_makespan'] != float('inf')])
            avg_load_balance = np.mean([r['hd_ddpg_result']['avg_load_balance'] for r in recent_results])

            # ç¨³å®šæ€§æŒ‡æ ‡
            makespan_stability = np.mean([r['stability_metrics']['makespan_stability'] for r in recent_results])
            avg_system_health = np.mean([r['system_health'] for r in recent_results])

            print(f"  ğŸ¯ å¹³å‡å¥–åŠ± (æœ€è¿‘{window_size}è½®): {avg_reward:.2f}")
            print(f"  â±ï¸ å¹³å‡Makespan (æœ€è¿‘{window_size}è½®): {avg_makespan:.3f}")
            print(f"  âš–ï¸ å¹³å‡è´Ÿè½½å‡è¡¡ (æœ€è¿‘{window_size}è½®): {avg_load_balance:.3f}")
            print(f"  ğŸ“ˆ Makespanç¨³å®šæ€§: {makespan_stability:.3f}")
            print(f"  ğŸ’Š ç³»ç»Ÿå¥åº·åº¦: {avg_system_health:.3f}")

            # ç›®æ ‡è¾¾æˆæƒ…å†µ
            target_makespan = self.config.get('makespan_target', 1.5)
            if avg_makespan <= target_makespan:
                print(f"  ğŸ‰ å·²è¾¾æˆMakespanç›®æ ‡! ({avg_makespan:.3f} <= {target_makespan})")
            else:
                gap = avg_makespan - target_makespan
                print(f"  ğŸ¯ è·ç¦»Makespanç›®æ ‡è¿˜å·®: {gap:.3f}")

        except Exception as e:
            print(f"  âš ï¸ æ€§èƒ½è¯„ä¼°é”™è¯¯: {e}")

    def _print_enhanced_progress(self, episode: int, total_episodes: int):
        """ğŸ¯ å¢å¼ºçš„è¿›åº¦æ‰“å°"""
        try:
            progress = episode / total_episodes * 100
            recent_results = self.simulation_results[-10:]

            if recent_results:
                avg_reward = np.mean([r['hd_ddpg_result']['total_reward'] for r in recent_results])
                avg_makespan = np.mean([r['hd_ddpg_result']['avg_makespan'] for r in recent_results
                                      if r['hd_ddpg_result']['avg_makespan'] != float('inf')])

                # ç¨³å®šæ€§æŒ‡æ ‡
                stability_score = np.mean([r.get('stability_metrics', {}).get('makespan_stability', 0)
                                         for r in recent_results])

                print(f"ğŸ“ˆ è¿›åº¦: {progress:.1f}% ({episode}/{total_episodes}) - "
                      f"å¥–åŠ±: {avg_reward:.2f}, Makespan: {avg_makespan:.3f}, "
                      f"ç¨³å®šæ€§: {stability_score:.3f}")

        except Exception as e:
            print(f"âš ï¸ è¿›åº¦æ‰“å°é”™è¯¯: {e}")

    def _save_enhanced_checkpoint(self, episode: int):
        """ğŸ¯ ä¿å­˜å¢å¼ºçš„æ£€æŸ¥ç‚¹"""
        try:
            checkpoint_path = f"models/stabilized_hd_ddpg_checkpoint_ep{episode}"
            self.hd_ddpg.save_models(checkpoint_path)

            # ä¿å­˜è¯¦ç»†çš„ä»¿çœŸç»“æœ
            enhanced_results = []
            for r in self.simulation_results:
                enhanced_result = {
                    'episode': r['episode'],
                    'workflows_count': r['workflows_count'],
                    'total_reward': r['hd_ddpg_result']['total_reward'],
                    'avg_makespan': r['hd_ddpg_result']['avg_makespan'],
                    'avg_load_balance': r['hd_ddpg_result']['avg_load_balance'],
                    'episode_duration': r['episode_duration'],
                    'makespan_stability': r.get('stability_metrics', {}).get('makespan_stability', 0),
                    'system_health': r.get('system_health', 0),
                    'convergence_indicator': r.get('convergence_indicator', 0),
                    'smoothed_makespan': r['hd_ddpg_result'].get('smoothed_makespan', 0)
                }
                enhanced_results.append(enhanced_result)

            # ä¿å­˜ä¸ºCSV
            results_df = pd.DataFrame(enhanced_results)
            results_df.to_csv(f"results/stabilized_simulation_results_ep{episode}.csv", index=False)

            # ä¿å­˜ç¨³å®šæ€§ç›‘æ§æ•°æ®
            stability_data = {
                'makespan_history': list(self.stability_monitor['makespan_history']),
                'reward_variance': list(self.stability_monitor['reward_variance']),
                'convergence_metrics': list(self.stability_monitor['convergence_metrics']),
                'system_health': list(self.stability_monitor['system_health']),
                'best_performance': self.best_performance
            }

            with open(f"results/stability_monitor_ep{episode}.json", 'w') as f:
                json.dump(stability_data, f, indent=2)

            print(f"âœ… å¢å¼ºæ£€æŸ¥ç‚¹å·²ä¿å­˜ (Episode {episode})")

        except Exception as e:
            print(f"âŒ ä¿å­˜å¢å¼ºæ£€æŸ¥ç‚¹é”™è¯¯: {e}")

    def _generate_episode_workflows(self, count: int = None) -> List[List[MedicalTask]]:
        """ğŸ¯ ç”Ÿæˆç¨³å®šåŒ–çš„episodeå·¥ä½œæµ"""
        if count is None:
            count = self.config['workflows_per_episode']

        workflows = []

        for _ in range(count):
            try:
                workflow_type = np.random.choice(self.config['workflow_types'])
                workflow_size = np.random.randint(
                    self.config['min_workflow_size'],
                    self.config['max_workflow_size'] + 1
                )

                workflow = self.workflow_generator.generate_workflow(
                    num_tasks=workflow_size,
                    workflow_type=workflow_type
                )
                workflows.append(workflow)

            except Exception as e:
                print(f"âš ï¸ å·¥ä½œæµç”Ÿæˆé”™è¯¯: {e}")
                # ç”Ÿæˆç®€å•çš„å¤‡ç”¨å·¥ä½œæµ
                backup_workflow = self._generate_backup_workflow()
                workflows.append(backup_workflow)

        return workflows

    def _generate_backup_workflow(self) -> List[MedicalTask]:
        """ç”Ÿæˆå¤‡ç”¨å·¥ä½œæµ"""
        # è¿™é‡Œåº”è¯¥åˆ›å»ºä¸€ä¸ªç®€å•çš„å¤‡ç”¨å·¥ä½œæµ
        # å…·ä½“å®ç°ä¾èµ–äºMedicalTaskçš„å®šä¹‰
        pass

    def _create_error_result(self, episode: int, error_msg: str) -> Dict:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return {
            'episode': episode + 1,
            'workflows_count': 0,
            'hd_ddpg_result': {
                'total_reward': -10.0,
                'avg_makespan': float('inf'),
                'avg_load_balance': 0.0,
                'episode_duration': 0.0,
                'success_rate': 0.0
            },
            'stability_metrics': {
                'makespan_stability': 0,
                'reward_consistency': 0,
                'performance_trend': 0,
                'target_achievement': 0
            },
            'episode_duration': 0.0,
            'initial_system_state': [0] * 15,
            'system_health': 0.0,
            'convergence_indicator': 0.0,
            'error': error_msg
        }

    def _generate_enhanced_final_report(self, simulation_duration: float) -> Dict:
        """ğŸ¯ ç”Ÿæˆå¢å¼ºçš„æœ€ç»ˆæŠ¥å‘Š"""
        if not self.simulation_results:
            return {'error': 'æ— ä»¿çœŸç»“æœ'}

        try:
            # æå–å…³é”®æŒ‡æ ‡
            rewards = [r['hd_ddpg_result']['total_reward'] for r in self.simulation_results]
            makespans = [r['hd_ddpg_result']['avg_makespan'] for r in self.simulation_results
                        if r['hd_ddpg_result']['avg_makespan'] != float('inf')]
            load_balances = [r['hd_ddpg_result']['avg_load_balance'] for r in self.simulation_results]

            # ç¨³å®šæ€§æŒ‡æ ‡
            stability_scores = [r.get('stability_metrics', {}).get('makespan_stability', 0)
                              for r in self.simulation_results]
            convergence_scores = [r.get('convergence_indicator', 0) for r in self.simulation_results]

            # è®¡ç®—æ”¹è¿›å¹…åº¦
            if len(rewards) >= 200:
                early_performance = np.mean(rewards[:100])
                late_performance = np.mean(rewards[-100:])
                reward_improvement = (late_performance - early_performance) / abs(early_performance) * 100
            else:
                reward_improvement = 0

            return {
                'simulation_summary': {
                    'total_episodes': len(self.simulation_results),
                    'simulation_duration': simulation_duration,
                    'total_workflows_processed': sum(r['workflows_count'] for r in self.simulation_results),
                    'average_episode_duration': np.mean([r['episode_duration'] for r in self.simulation_results]),
                    'convergence_achieved': self._check_convergence(len(self.simulation_results) - 1)
                },
                'performance_metrics': {
                    'final_avg_reward': np.mean(rewards[-100:]) if len(rewards) >= 100 else np.mean(rewards),
                    'final_avg_makespan': np.mean(makespans[-100:]) if len(makespans) >= 100 else np.mean(makespans),
                    'final_avg_load_balance': np.mean(load_balances[-100:]) if len(load_balances) >= 100 else np.mean(load_balances),
                    'reward_improvement_percent': reward_improvement,
                    'best_makespan_achieved': self.best_performance['makespan'],
                    'best_makespan_episode': self.best_performance['episode']
                },
                'stability_analysis': {
                    'avg_makespan_stability': np.mean(stability_scores[-50:]) if len(stability_scores) >= 50 else np.mean(stability_scores),
                    'avg_convergence_score': np.mean(convergence_scores[-50:]) if len(convergence_scores) >= 50 else np.mean(convergence_scores),
                    'makespan_variance': np.var(makespans[-100:]) if len(makespans) >= 100 else np.var(makespans),
                    'reward_variance': np.var(rewards[-100:]) if len(rewards) >= 100 else np.var(rewards),
                    'system_health_avg': np.mean(list(self.stability_monitor['system_health'])[-20:]) if len(self.stability_monitor['system_health']) >= 20 else np.mean(list(self.stability_monitor['system_health']))
                },
                'training_convergence': {
                    'reward_trend': rewards,
                    'makespan_trend': makespans,
                    'load_balance_trend': load_balances,
                    'stability_trend': stability_scores,
                    'convergence_trend': convergence_scores
                },
                'optimization_achievements': {
                    'target_makespan': self.config.get('makespan_target', 1.5),
                    'target_achieved': self.best_performance['makespan'] <= self.config.get('makespan_target', 1.5),
                    'improvement_over_baseline': 'TBD',  # éœ€è¦åŸºçº¿å¯¹æ¯”
                    'stability_improvement': 'Significant' if np.mean(stability_scores[-20:]) > 0.7 else 'Moderate'
                }
            }

        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¢å¼ºæœ€ç»ˆæŠ¥å‘Šé”™è¯¯: {e}")
            return {'error': f'æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}'}

    # ğŸ¯ ä¿ç•™åŸæœ‰çš„åŸºçº¿å¯¹æ¯”åŠŸèƒ½ï¼ˆç•¥å¾®ä¼˜åŒ–ï¼‰
    def compare_with_baseline(self, baseline_algorithms: List[str] = None) -> Dict:
        """ä¸åŸºçº¿ç®—æ³•æ¯”è¾ƒ"""
        if baseline_algorithms is None:
            baseline_algorithms = ['HEFT', 'FCFS', 'Random']

        print("ğŸ” å¯¹æ¯”HD-DDPGä¸åŸºçº¿ç®—æ³•æ€§èƒ½...")

        # ç”Ÿæˆæµ‹è¯•å·¥ä½œæµé›†
        test_workflows = self.workflow_generator.generate_batch_workflows(batch_size=100)  # å¢åŠ æµ‹è¯•æ•°é‡

        comparison_results = {'HD-DDPG': []}

        # HD-DDPGæ€§èƒ½
        print("  æµ‹è¯•HD-DDPGæ€§èƒ½...")
        for i, workflow in enumerate(test_workflows):
            if i % 20 == 0:
                print(f"    è¿›åº¦: {i+1}/{len(test_workflows)}")

            self.environment.reset()
            result = self.hd_ddpg.schedule_workflow(workflow, self.environment)
            comparison_results['HD-DDPG'].append({
                'makespan': result['makespan'],
                'load_balance': result['load_balance'],
                'energy': result['total_energy'],
                'completed_tasks': result['completed_tasks']
            })

        # åŸºçº¿ç®—æ³•æ€§èƒ½
        for algorithm in baseline_algorithms:
            print(f"  æµ‹è¯•{algorithm}æ€§èƒ½...")
            comparison_results[algorithm] = []
            for i, workflow in enumerate(test_workflows):
                if i % 20 == 0:
                    print(f"    è¿›åº¦: {i+1}/{len(test_workflows)}")

                self.environment.reset()
                result = self._run_baseline_algorithm(algorithm, workflow)
                comparison_results[algorithm].append(result)

        # è®¡ç®—ç»Ÿè®¡æ¯”è¾ƒ
        stats_comparison = self._calculate_comparison_stats(comparison_results)

        print("âœ… åŸºçº¿å¯¹æ¯”å®Œæˆ")
        return {
            'detailed_results': comparison_results,
            'statistical_comparison': stats_comparison,
            'test_workflows_count': len(test_workflows)
        }

    # ä¿ç•™åŸæœ‰çš„å¯è§†åŒ–åŠŸèƒ½ï¼ˆç¨ä½œå¢å¼ºï¼‰
    def visualize_results(self, save_path: str = None):
        """ğŸ¯ å¢å¼ºçš„ç»“æœå¯è§†åŒ–"""
        if not self.simulation_results:
            print("æ— ä»¿çœŸç»“æœå¯è§†åŒ–")
            return

        # æå–æ•°æ®
        episodes = [r['episode'] for r in self.simulation_results]
        rewards = [r['hd_ddpg_result']['total_reward'] for r in self.simulation_results]
        makespans = [r['hd_ddpg_result']['avg_makespan'] for r in self.simulation_results
                    if r['hd_ddpg_result']['avg_makespan'] != float('inf')]
        load_balances = [r['hd_ddpg_result']['avg_load_balance'] for r in self.simulation_results]
        stability_scores = [r.get('stability_metrics', {}).get('makespan_stability', 0)
                          for r in self.simulation_results]

        # åˆ›å»ºå¢å¼ºçš„å›¾å½¢
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # å¥–åŠ±è¶‹åŠ¿
        axes[0, 0].plot(episodes, rewards, alpha=0.7, color='blue')
        if len(rewards) >= 50:
            axes[0, 0].plot(episodes, self._moving_average(rewards, 50), 'r-', linewidth=2, label='50-episode MA')
        axes[0, 0].set_title('Training Rewards')
        axes[0, 0].set_xlabel('Episode')
        axes[0, 0].set_ylabel('Total Reward')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # Makespanè¶‹åŠ¿
        makespan_episodes = episodes[:len(makespans)]
        axes[0, 1].plot(makespan_episodes, makespans, alpha=0.7, color='green')
        if len(makespans) >= 50:
            axes[0, 1].plot(makespan_episodes, self._moving_average(makespans, 50), 'r-', linewidth=2, label='50-episode MA')

        # æ·»åŠ ç›®æ ‡çº¿
        target_makespan = self.config.get('makespan_target', 1.5)
        axes[0, 1].axhline(y=target_makespan, color='red', linestyle='--', label=f'Target: {target_makespan}')

        axes[0, 1].set_title('Average Makespan')
        axes[0, 1].set_xlabel('Episode')
        axes[0, 1].set_ylabel('Makespan')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # è´Ÿè½½å‡è¡¡è¶‹åŠ¿
        axes[0, 2].plot(episodes, load_balances, alpha=0.7, color='orange')
        if len(load_balances) >= 50:
            axes[0, 2].plot(episodes, self._moving_average(load_balances, 50), 'r-', linewidth=2, label='50-episode MA')
        axes[0, 2].set_title('Load Balance Score')
        axes[0, 2].set_xlabel('Episode')
        axes[0, 2].set_ylabel('Load Balance')
        axes[0, 2].legend()
        axes[0, 2].grid(True)

        # ğŸ¯ æ–°å¢ï¼šç¨³å®šæ€§è¶‹åŠ¿
        axes[1, 0].plot(episodes, stability_scores, alpha=0.7, color='purple')
        if len(stability_scores) >= 30:
            axes[1, 0].plot(episodes, self._moving_average(stability_scores, 30), 'r-', linewidth=2, label='30-episode MA')
        axes[1, 0].set_title('Makespan Stability Score')
        axes[1, 0].set_xlabel('Episode')
        axes[1, 0].set_ylabel('Stability Score')
        axes[1, 0].legend()
        axes[1, 0].grid(True)

        # æ€§èƒ½åˆ†å¸ƒ
        axes[1, 1].hist(rewards[-200:], bins=30, alpha=0.7, color='skyblue', label='Recent 200 episodes')
        axes[1, 1].set_title('Reward Distribution (Recent)')
        axes[1, 1].set_xlabel('Total Reward')
        axes[1, 1].set_ylabel('Frequency')
        axes[1, 1].legend()
        axes[1, 1].grid(True)

        # ğŸ¯ æ–°å¢ï¼šMakespanåˆ†å¸ƒ
        if len(makespans) >= 100:
            axes[1, 2].hist(makespans[-100:], bins=25, alpha=0.7, color='lightcoral', label='Recent 100 episodes')
            axes[1, 2].axvline(x=target_makespan, color='red', linestyle='--', label=f'Target: {target_makespan}')
            axes[1, 2].set_title('Makespan Distribution (Recent)')
            axes[1, 2].set_xlabel('Makespan')
            axes[1, 2].set_ylabel('Frequency')
            axes[1, 2].legend()
            axes[1, 2].grid(True)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
        plt.show()

    # ä¿ç•™å…¶ä»–åŸæœ‰æ–¹æ³•...
    def _moving_average(self, data: List, window_size: int) -> List:
        """è®¡ç®—ç§»åŠ¨å¹³å‡"""
        if len(data) < window_size:
            return data

        moving_avg = []
        for i in range(len(data)):
            start_idx = max(0, i - window_size + 1)
            moving_avg.append(np.mean(data[start_idx:i + 1]))

        return moving_avg

    # ä¿ç•™åŸæœ‰çš„åŸºçº¿ç®—æ³•å®ç°...
    def _run_baseline_algorithm(self, algorithm: str, workflow: List[MedicalTask]) -> Dict:
        """è¿è¡ŒåŸºçº¿ç®—æ³•"""
        if algorithm == 'HEFT':
            return self._heft_scheduling(workflow)
        elif algorithm == 'FCFS':
            return self._fcfs_scheduling(workflow)
        elif algorithm == 'Random':
            return self._random_scheduling(workflow)
        else:
            return {'makespan': float('inf'), 'load_balance': 0, 'energy': float('inf'), 'completed_tasks': 0}

    def _heft_scheduling(self, workflow: List[MedicalTask]) -> Dict:
        """HEFTåŸºçº¿ç®—æ³•"""
        task_completion_times = []
        total_energy = 0

        # æŒ‰ç…§ä¼˜å…ˆçº§æ’åºä»»åŠ¡
        sorted_tasks = sorted(workflow, key=lambda t: t.priority, reverse=True)

        for task in sorted_tasks:
            # é€‰æ‹©æœ€å¿«çš„å¯ç”¨èŠ‚ç‚¹
            all_nodes = self.environment.get_available_nodes()
            if all_nodes:
                best_node = min(all_nodes, key=lambda n: n.get_execution_time(task.computation_requirement))

                if best_node.can_accommodate(task.memory_requirement):
                    execution_time = best_node.get_execution_time(task.computation_requirement)
                    energy = best_node.get_energy_consumption(execution_time)

                    task_completion_times.append(execution_time)
                    total_energy += energy

                    self.environment.update_node_load(best_node.node_id, task.memory_requirement)

        makespan = max(task_completion_times) if task_completion_times else 0

        # è®¡ç®—è´Ÿè½½å‡è¡¡
        node_loads = [node.current_load / node.memory_capacity
                      for node_list in self.environment.nodes.values()
                      for node in node_list]
        load_balance = self.metrics.calculate_load_balance(node_loads)

        return {
            'makespan': makespan,
            'load_balance': load_balance,
            'energy': total_energy,
            'completed_tasks': len(task_completion_times)
        }

    def _fcfs_scheduling(self, workflow: List[MedicalTask]) -> Dict:
        """FCFSåŸºçº¿ç®—æ³•"""
        task_completion_times = []
        total_energy = 0

        for task in workflow:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨èŠ‚ç‚¹
            all_nodes = self.environment.get_available_nodes()
            if all_nodes:
                selected_node = all_nodes[0]

                if selected_node.can_accommodate(task.memory_requirement):
                    execution_time = selected_node.get_execution_time(task.computation_requirement)
                    energy = selected_node.get_energy_consumption(execution_time)

                    task_completion_times.append(execution_time)
                    total_energy += energy

                    self.environment.update_node_load(selected_node.node_id, task.memory_requirement)

        makespan = max(task_completion_times) if task_completion_times else 0

        node_loads = [node.current_load / node.memory_capacity
                      for node_list in self.environment.nodes.values()
                      for node in node_list]
        load_balance = self.metrics.calculate_load_balance(node_loads)

        return {
            'makespan': makespan,
            'load_balance': load_balance,
            'energy': total_energy,
            'completed_tasks': len(task_completion_times)
        }

    def _random_scheduling(self, workflow: List[MedicalTask]) -> Dict:
        """éšæœºè°ƒåº¦åŸºçº¿ç®—æ³•"""
        task_completion_times = []
        total_energy = 0

        for task in workflow:
            all_nodes = self.environment.get_available_nodes()
            if all_nodes:
                selected_node = np.random.choice(all_nodes)

                if selected_node.can_accommodate(task.memory_requirement):
                    execution_time = selected_node.get_execution_time(task.computation_requirement)
                    energy = selected_node.get_energy_consumption(execution_time)

                    task_completion_times.append(execution_time)
                    total_energy += energy

                    self.environment.update_node_load(selected_node.node_id, task.memory_requirement)

        makespan = max(task_completion_times) if task_completion_times else 0

        node_loads = [node.current_load / node.memory_capacity
                      for node_list in self.environment.nodes.values()
                      for node in node_list]
        load_balance = self.metrics.calculate_load_balance(node_loads)

        return {
            'makespan': makespan,
            'load_balance': load_balance,
            'energy': total_energy,
            'completed_tasks': len(task_completion_times)
        }

    def _calculate_comparison_stats(self, comparison_results: Dict) -> Dict:
        """è®¡ç®—æ¯”è¾ƒç»Ÿè®¡"""
        stats = {}

        for algorithm, results in comparison_results.items():
            makespans = [r['makespan'] for r in results if r['makespan'] != float('inf')]
            load_balances = [r['load_balance'] for r in results]
            energies = [r['energy'] for r in results if r['energy'] != float('inf')]

            stats[algorithm] = {
                'avg_makespan': np.mean(makespans) if makespans else float('inf'),
                'std_makespan': np.std(makespans) if makespans else 0,
                'avg_load_balance': np.mean(load_balances),
                'std_load_balance': np.std(load_balances),
                'avg_energy': np.mean(energies) if energies else float('inf'),
                'std_energy': np.std(energies) if energies else 0
            }

        return stats


# ğŸ¯ ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸå§‹ç±»å
MedicalSchedulingSimulator = StabilizedMedicalSchedulingSimulator


# ğŸ§ª å¢å¼ºçš„æµ‹è¯•å‡½æ•°
def test_stabilized_medical_simulator():
    """æµ‹è¯•ç¨³å®šåŒ–åŒ»ç–—ä»¿çœŸå™¨"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•StabilizedMedicalSchedulingSimulator...")

    try:
        # åˆ›å»ºç¨³å®šåŒ–ä»¿çœŸå™¨
        config = {
            'simulation_episodes': 20,
            'workflows_per_episode': 5,
            'makespan_target': 1.6,
            'stability_monitoring': True,
            'state_smoothing': True
        }

        simulator = StabilizedMedicalSchedulingSimulator(config)

        # æµ‹è¯•1: åŸºæœ¬ä»¿çœŸ
        print("\nğŸ“ æµ‹è¯•1: åŸºæœ¬ä»¿çœŸæµ‹è¯•")
        test_result = simulator.run_simulation(episodes=10)
        print(f"âœ… ä»¿çœŸå®Œæˆï¼Œæœ€ç»ˆæŠ¥å‘Šå…³é”®æŒ‡æ ‡:")
        print(f"  - æœ€ä½³Makespan: {test_result['performance_metrics']['best_makespan_achieved']:.3f}")
        print(f"  - ç¨³å®šæ€§è¯„åˆ†: {test_result['stability_analysis']['avg_makespan_stability']:.3f}")

        # æµ‹è¯•2: å¯è§†åŒ–
        print("\nğŸ“ æµ‹è¯•2: å¯è§†åŒ–æµ‹è¯•")
        simulator.visualize_results("results/test_stabilized_simulation.png")
        print("âœ… å¯è§†åŒ–æµ‹è¯•å®Œæˆ")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼StabilizedMedicalSchedulingSimulatorå·¥ä½œæ­£å¸¸")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = test_stabilized_medical_simulator()
    if success:
        print("\nâœ… Stabilized Medical Scheduling Simulator ready for production!")
        print("ğŸ¯ ä¸»è¦ä¼˜åŒ–:")
        print("  - çŠ¶æ€ç®¡ç†ç¨³å®šåŒ–: å‡å°‘è¾“å…¥å™ªå£°")
        print("  - å®æ—¶ç¨³å®šæ€§ç›‘æ§: æŒç»­è·Ÿè¸ªæ€§èƒ½")
        print("  - æ™ºèƒ½æ”¶æ•›æ£€æµ‹: è‡ªåŠ¨åœæ­¢è®­ç»ƒ")
        print("  - å¢å¼ºé”™è¯¯å¤„ç†: é²æ£’æ€§æå‡")
        print("  - ç›®æ ‡å¯¼å‘è®­ç»ƒ: æ˜ç¡®æ€§èƒ½ç›®æ ‡")
    else:
        print("\nâŒ Stabilized Medical Scheduling Simulator needs debugging!")