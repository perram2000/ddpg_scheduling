"""
Hierarchical Replay Buffer - é«˜åº¦ä¼˜åŒ–ç‰ˆæœ¬
åˆ†å±‚å›æ”¾ç¼“å†²åŒºå®ç° - ä¸“ä¸ºç¨³å®šåŒ–HD-DDPGè®¾è®¡

ğŸ¯ ä¸»è¦ä¼˜åŒ–ï¼š
- ä¼˜å…ˆçº§ç»éªŒå›æ”¾ (PER)
- ç»éªŒè´¨é‡è¯„ä¼°
- ç¨³å®šåŒ–é‡‡æ ·ç­–ç•¥
- å†…å­˜ä¼˜åŒ–ç®¡ç†
- å¼‚å¸¸ç»éªŒè¿‡æ»¤
"""

import random
import numpy as np
from collections import deque
from typing import Tuple, List, Optional, Dict
import heapq
from dataclasses import dataclass
import time


@dataclass
class Experience:
    """å¢å¼ºçš„ç»éªŒæ•°æ®ç»“æ„"""
    state: np.ndarray
    action: np.ndarray
    reward: float
    next_state: np.ndarray
    done: bool
    priority: float = 1.0
    timestamp: float = None
    quality_score: float = 1.0
    cluster_type: str = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()


class PrioritizedExperienceReplay:
    """
    ä¼˜å…ˆçº§ç»éªŒå›æ”¾å®ç°
    åŸºäºTD-errorçš„ä¼˜å…ˆçº§é‡‡æ ·
    """

    def __init__(self, capacity: int, alpha: float = 0.6, beta: float = 0.4,
                 beta_increment: float = 0.001):
        """
        åˆå§‹åŒ–ä¼˜å…ˆçº§ç»éªŒå›æ”¾

        Args:
            capacity: ç¼“å†²åŒºå®¹é‡
            alpha: ä¼˜å…ˆçº§æŒ‡æ•°
            beta: é‡è¦æ€§é‡‡æ ·æŒ‡æ•°
            beta_increment: betaé€’å¢ç‡
        """
        self.capacity = capacity
        self.alpha = alpha
        self.beta = beta
        self.beta_increment = beta_increment
        self.max_beta = 1.0

        # ä½¿ç”¨numpyæ•°ç»„å­˜å‚¨ä»¥æé«˜æ•ˆç‡
        self.buffer = []
        self.priorities = deque(maxlen=capacity)
        self.position = 0

    def add(self, experience: Experience):
        """æ·»åŠ ç»éªŒåˆ°ç¼“å†²åŒº"""
        max_priority = max(self.priorities) if self.priorities else 1.0

        if len(self.buffer) < self.capacity:
            self.buffer.append(experience)
        else:
            self.buffer[self.position] = experience

        self.priorities.append(max_priority)
        self.position = (self.position + 1) % self.capacity

    def sample(self, batch_size: int) -> Tuple[List[Experience], np.ndarray, np.ndarray]:
        """ä¼˜å…ˆçº§é‡‡æ ·"""
        if len(self.buffer) == 0:
            return [], np.array([]), np.array([])

        # è®¡ç®—é‡‡æ ·æ¦‚ç‡
        priorities = np.array(list(self.priorities))
        probs = priorities ** self.alpha
        probs /= probs.sum()

        # é‡‡æ ·ç´¢å¼•
        indices = np.random.choice(len(self.buffer), batch_size, p=probs, replace=True)

        # è®¡ç®—é‡è¦æ€§æƒé‡
        weights = (len(self.buffer) * probs[indices]) ** (-self.beta)
        weights /= weights.max()

        # æ›´æ–°beta
        self.beta = min(self.max_beta, self.beta + self.beta_increment)

        experiences = [self.buffer[idx] for idx in indices]

        return experiences, indices, weights

    def update_priorities(self, indices: np.ndarray, priorities: np.ndarray):
        """æ›´æ–°ä¼˜å…ˆçº§"""
        for idx, priority in zip(indices, priorities):
            if 0 <= idx < len(self.priorities):
                self.priorities[idx] = priority

    def __len__(self):
        return len(self.buffer)


class StabilizedHierarchicalReplayBuffer:
    """
    ç¨³å®šåŒ–åˆ†å±‚å›æ”¾ç¼“å†²åŒº
    ğŸ¯ ä¸“ä¸ºç¨³å®šåŒ–è®­ç»ƒè®¾è®¡çš„é«˜çº§å›æ”¾ç¼“å†²åŒº
    """

    def __init__(self, capacity: int = 10000, enable_per: bool = True,
                 quality_threshold: float = 0.1, balance_sampling: bool = True):
        """
        åˆå§‹åŒ–ç¨³å®šåŒ–åˆ†å±‚å›æ”¾ç¼“å†²åŒº

        Args:
            capacity: æ€»ç¼“å†²åŒºå®¹é‡
            enable_per: æ˜¯å¦å¯ç”¨ä¼˜å…ˆçº§ç»éªŒå›æ”¾
            quality_threshold: ç»éªŒè´¨é‡é˜ˆå€¼
            balance_sampling: æ˜¯å¦å¯ç”¨å¹³è¡¡é‡‡æ ·
        """
        self.capacity = capacity
        self.enable_per = enable_per
        self.quality_threshold = quality_threshold
        self.balance_sampling = balance_sampling

        print(f"ğŸ”§ åˆå§‹åŒ–StabilizedHierarchicalReplayBuffer...")
        print(f"  - å®¹é‡: {capacity}")
        print(f"  - ä¼˜å…ˆçº§å›æ”¾: {'å¯ç”¨' if enable_per else 'ç¦ç”¨'}")
        print(f"  - è´¨é‡é˜ˆå€¼: {quality_threshold}")
        print(f"  - å¹³è¡¡é‡‡æ ·: {'å¯ç”¨' if balance_sampling else 'ç¦ç”¨'}")

        # ğŸ¯ å…ƒæ§åˆ¶å™¨ç¼“å†²åŒº
        if enable_per:
            self.meta_buffer = PrioritizedExperienceReplay(capacity // 2)
        else:
            self.meta_buffer = deque(maxlen=capacity // 2)

        # ğŸ¯ å­æ§åˆ¶å™¨ç¼“å†²åŒº (æ”¯æŒä¼˜å…ˆçº§)
        sub_capacity = capacity // 6  # æ¯ä¸ªé›†ç¾¤1/6å®¹é‡
        self.sub_buffers = {}
        for cluster_type in ['FPGA', 'FOG_GPU', 'CLOUD']:
            if enable_per:
                self.sub_buffers[cluster_type] = PrioritizedExperienceReplay(sub_capacity)
            else:
                self.sub_buffers[cluster_type] = deque(maxlen=sub_capacity)

        # ğŸ¯ ç»éªŒè´¨é‡ç›‘æ§
        self.quality_monitor = {
            'total_experiences': 0,
            'filtered_experiences': 0,
            'meta_quality_history': deque(maxlen=1000),
            'sub_quality_history': {cluster: deque(maxlen=1000) for cluster in ['FPGA', 'FOG_GPU', 'CLOUD']}
        }

        # ğŸ¯ é‡‡æ ·ç»Ÿè®¡
        self.sampling_stats = {
            'meta_samples': 0,
            'sub_samples': {cluster: 0 for cluster in ['FPGA', 'FOG_GPU', 'CLOUD']},
            'quality_filtered': 0,
            'last_sample_time': time.time()
        }

        print("âœ… ç¨³å®šåŒ–åˆ†å±‚å›æ”¾ç¼“å†²åŒºåˆå§‹åŒ–å®Œæˆ")

    def _calculate_experience_quality(self, state: np.ndarray, action: np.ndarray,
                                    reward: float, next_state: np.ndarray, done: bool) -> float:
        """ğŸ¯ è®¡ç®—ç»éªŒè´¨é‡è¯„åˆ†"""
        try:
            quality_score = 1.0

            # ğŸ¯ çŠ¶æ€è´¨é‡æ£€æŸ¥
            if np.any(np.isnan(state)) or np.any(np.isinf(state)):
                quality_score *= 0.1

            if np.any(np.isnan(next_state)) or np.any(np.isinf(next_state)):
                quality_score *= 0.1

            # ğŸ¯ åŠ¨ä½œè´¨é‡æ£€æŸ¥
            if np.any(np.isnan(action)) or np.any(np.isinf(action)):
                quality_score *= 0.1

            # åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒæ£€æŸ¥ï¼ˆå¯¹äºæ¦‚ç‡åŠ¨ä½œï¼‰
            if len(action) > 1 and np.sum(action) > 0:
                action_entropy = -np.sum(action * np.log(action + 1e-8))
                max_entropy = -np.log(1.0 / len(action))
                entropy_ratio = action_entropy / max_entropy
                # å¥–åŠ±é€‚åº¦çš„æ¢ç´¢
                quality_score *= (0.7 + 0.6 * entropy_ratio)

            # ğŸ¯ å¥–åŠ±è´¨é‡æ£€æŸ¥
            if np.isnan(reward) or np.isinf(reward):
                quality_score *= 0.01
            elif abs(reward) > 1000:  # å¼‚å¸¸å¤§çš„å¥–åŠ±
                quality_score *= 0.3

            # ğŸ¯ çŠ¶æ€å˜åŒ–æ£€æŸ¥
            if not done:
                state_change = np.linalg.norm(next_state - state)
                if state_change == 0:  # çŠ¶æ€æ²¡æœ‰å˜åŒ–
                    quality_score *= 0.5
                elif state_change > 10:  # çŠ¶æ€å˜åŒ–è¿‡å¤§
                    quality_score *= 0.7

            return np.clip(quality_score, 0.01, 1.0)

        except Exception as e:
            print(f"âš ï¸ ç»éªŒè´¨é‡è®¡ç®—é”™è¯¯: {e}")
            return 0.1

    def _calculate_priority(self, reward: float, quality_score: float,
                          cluster_type: str = None) -> float:
        """ğŸ¯ è®¡ç®—ç»éªŒä¼˜å…ˆçº§"""
        try:
            # åŸºç¡€ä¼˜å…ˆçº§åŸºäºå¥–åŠ±ç»å¯¹å€¼
            base_priority = abs(reward) + 1e-6

            # ğŸ¯ è´¨é‡åŠ æƒ
            priority = base_priority * quality_score

            # ğŸ¯ é›†ç¾¤ç‰¹åŒ–æƒé‡
            if cluster_type:
                cluster_weights = {'FPGA': 1.2, 'FOG_GPU': 1.0, 'CLOUD': 0.8}
                priority *= cluster_weights.get(cluster_type, 1.0)

            # ğŸ¯ ç¨€æœ‰ç»éªŒå¥–åŠ±ï¼ˆé«˜è´¨é‡ä½é¢‘ç»éªŒï¼‰
            if quality_score > 0.8 and abs(reward) > 10:
                priority *= 1.5

            return max(priority, 1e-6)

        except Exception as e:
            print(f"âš ï¸ ä¼˜å…ˆçº§è®¡ç®—é”™è¯¯: {e}")
            return 1.0

    def push_meta(self, state: np.ndarray, action: np.ndarray, reward: float,
                  next_state: np.ndarray, done: bool):
        """ğŸ¯ æ·»åŠ å…ƒæ§åˆ¶å™¨ç»éªŒï¼ˆæ”¯æŒè´¨é‡è¿‡æ»¤å’Œä¼˜å…ˆçº§ï¼‰"""
        try:
            # ğŸ¯ è®¡ç®—ç»éªŒè´¨é‡
            quality_score = self._calculate_experience_quality(state, action, reward, next_state, done)

            # ğŸ¯ è´¨é‡è¿‡æ»¤
            if quality_score < self.quality_threshold:
                self.quality_monitor['filtered_experiences'] += 1
                return False

            # ğŸ¯ åˆ›å»ºç»éªŒå¯¹è±¡
            experience = Experience(
                state=state.copy(),
                action=action.copy(),
                reward=reward,
                next_state=next_state.copy(),
                done=done,
                quality_score=quality_score,
                cluster_type='META'
            )

            # ğŸ¯ è®¡ç®—ä¼˜å…ˆçº§
            if self.enable_per:
                priority = self._calculate_priority(reward, quality_score)
                experience.priority = priority
                self.meta_buffer.add(experience)
            else:
                self.meta_buffer.append(experience)

            # ğŸ¯ æ›´æ–°ç›‘æ§ç»Ÿè®¡
            self.quality_monitor['total_experiences'] += 1
            self.quality_monitor['meta_quality_history'].append(quality_score)

            return True

        except Exception as e:
            print(f"âš ï¸ å…ƒæ§åˆ¶å™¨ç»éªŒæ·»åŠ é”™è¯¯: {e}")
            return False

    def push_sub(self, cluster_type: str, state: np.ndarray, action: np.ndarray,
                 reward: float, next_state: np.ndarray, done: bool):
        """ğŸ¯ æ·»åŠ å­æ§åˆ¶å™¨ç»éªŒï¼ˆæ”¯æŒè´¨é‡è¿‡æ»¤å’Œä¼˜å…ˆçº§ï¼‰"""
        try:
            if cluster_type not in self.sub_buffers:
                print(f"âš ï¸ æœªçŸ¥é›†ç¾¤ç±»å‹: {cluster_type}")
                return False

            # ğŸ¯ è®¡ç®—ç»éªŒè´¨é‡
            quality_score = self._calculate_experience_quality(state, action, reward, next_state, done)

            # ğŸ¯ è´¨é‡è¿‡æ»¤
            if quality_score < self.quality_threshold:
                self.quality_monitor['filtered_experiences'] += 1
                return False

            # ğŸ¯ åˆ›å»ºç»éªŒå¯¹è±¡
            experience = Experience(
                state=state.copy(),
                action=action.copy(),
                reward=reward,
                next_state=next_state.copy(),
                done=done,
                quality_score=quality_score,
                cluster_type=cluster_type
            )

            # ğŸ¯ è®¡ç®—ä¼˜å…ˆçº§
            if self.enable_per:
                priority = self._calculate_priority(reward, quality_score, cluster_type)
                experience.priority = priority
                self.sub_buffers[cluster_type].add(experience)
            else:
                self.sub_buffers[cluster_type].append(experience)

            # ğŸ¯ æ›´æ–°ç›‘æ§ç»Ÿè®¡
            self.quality_monitor['total_experiences'] += 1
            self.quality_monitor['sub_quality_history'][cluster_type].append(quality_score)

            return True

        except Exception as e:
            print(f"âš ï¸ å­æ§åˆ¶å™¨ç»éªŒæ·»åŠ é”™è¯¯ ({cluster_type}): {e}")
            return False

    def can_sample(self, batch_size: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»å…ƒæ§åˆ¶å™¨ç¼“å†²åŒºé‡‡æ ·"""
        return len(self.meta_buffer) >= batch_size

    def can_sample_sub(self, cluster_type: str, batch_size: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä»æŒ‡å®šé›†ç¾¤çš„å­ç¼“å†²åŒºé‡‡æ ·"""
        if cluster_type not in self.sub_buffers:
            return False
        return len(self.sub_buffers[cluster_type]) >= batch_size

    def sample_meta(self, batch_size: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray,
                                                   np.ndarray, np.ndarray, Optional[np.ndarray]]:
        """ğŸ¯ ä»å…ƒæ§åˆ¶å™¨ç¼“å†²åŒºç¨³å®šåŒ–é‡‡æ ·"""
        try:
            if not self.can_sample(batch_size):
                # è¿”å›é»˜è®¤æ•°æ®
                dummy_state = np.zeros((batch_size, 15), dtype=np.float32)
                dummy_action = np.zeros((batch_size, 3), dtype=np.float32)
                dummy_reward = np.zeros((batch_size, 1), dtype=np.float32)
                dummy_next_state = np.zeros((batch_size, 15), dtype=np.float32)
                dummy_done = np.zeros((batch_size, 1), dtype=np.float32)
                return dummy_state, dummy_action, dummy_reward, dummy_next_state, dummy_done, None

            # ğŸ¯ ä¼˜å…ˆçº§é‡‡æ ·
            if self.enable_per:
                experiences, indices, weights = self.meta_buffer.sample(batch_size)
                importance_weights = weights
            else:
                experiences = random.sample(list(self.meta_buffer), batch_size)
                indices = None
                importance_weights = None

            # ğŸ¯ æ•°æ®è½¬æ¢å’ŒéªŒè¯
            states = []
            actions = []
            rewards = []
            next_states = []
            dones = []

            for exp in experiences:
                # æ•°æ®éªŒè¯
                if (not np.any(np.isnan(exp.state)) and not np.any(np.isnan(exp.next_state)) and
                    not np.any(np.isnan(exp.action)) and not np.isnan(exp.reward)):
                    states.append(exp.state)
                    actions.append(exp.action)
                    rewards.append(exp.reward)
                    next_states.append(exp.next_state)
                    dones.append(float(exp.done))

            # å¦‚æœè¿‡æ»¤åæ•°æ®ä¸è¶³ï¼Œç”¨é»˜è®¤æ•°æ®è¡¥é½
            while len(states) < batch_size:
                states.append(np.zeros(15, dtype=np.float32))
                actions.append(np.zeros(3, dtype=np.float32))
                rewards.append(0.0)
                next_states.append(np.zeros(15, dtype=np.float32))
                dones.append(0.0)

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            states = np.array(states[:batch_size], dtype=np.float32)
            actions = np.array(actions[:batch_size], dtype=np.float32)
            rewards = np.array(rewards[:batch_size], dtype=np.float32).reshape(-1, 1)
            next_states = np.array(next_states[:batch_size], dtype=np.float32)
            dones = np.array(dones[:batch_size], dtype=np.float32).reshape(-1, 1)

            # ğŸ¯ æ›´æ–°é‡‡æ ·ç»Ÿè®¡
            self.sampling_stats['meta_samples'] += 1
            self.sampling_stats['last_sample_time'] = time.time()

            return states, actions, rewards, next_states, dones, importance_weights

        except Exception as e:
            print(f"âš ï¸ å…ƒæ§åˆ¶å™¨é‡‡æ ·é”™è¯¯: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤æ•°æ®
            dummy_state = np.zeros((batch_size, 15), dtype=np.float32)
            dummy_action = np.zeros((batch_size, 3), dtype=np.float32)
            dummy_reward = np.zeros((batch_size, 1), dtype=np.float32)
            dummy_next_state = np.zeros((batch_size, 15), dtype=np.float32)
            dummy_done = np.zeros((batch_size, 1), dtype=np.float32)
            return dummy_state, dummy_action, dummy_reward, dummy_next_state, dummy_done, None

    def sample_sub(self, cluster_type: str, batch_size: int) -> Tuple[np.ndarray, np.ndarray,
                                                                    np.ndarray, np.ndarray,
                                                                    np.ndarray, Optional[np.ndarray]]:
        """ğŸ¯ ä»æŒ‡å®šé›†ç¾¤å­ç¼“å†²åŒºç¨³å®šåŒ–é‡‡æ ·"""
        try:
            # è·å–é›†ç¾¤çŠ¶æ€ç»´åº¦
            state_dims = {'FPGA': 6, 'FOG_GPU': 8, 'CLOUD': 6}
            action_dims = {'FPGA': 2, 'FOG_GPU': 3, 'CLOUD': 2}
            state_dim = state_dims.get(cluster_type, 6)
            action_dim = action_dims.get(cluster_type, 2)

            if not self.can_sample_sub(cluster_type, batch_size):
                # è¿”å›é›†ç¾¤ç‰¹åŒ–çš„é»˜è®¤æ•°æ®
                dummy_state = np.zeros((batch_size, state_dim), dtype=np.float32)
                dummy_action = np.zeros((batch_size, action_dim), dtype=np.float32)
                dummy_reward = np.zeros((batch_size, 1), dtype=np.float32)
                dummy_next_state = np.zeros((batch_size, state_dim), dtype=np.float32)
                dummy_done = np.zeros((batch_size, 1), dtype=np.float32)
                return dummy_state, dummy_action, dummy_reward, dummy_next_state, dummy_done, None

            # ğŸ¯ ä¼˜å…ˆçº§é‡‡æ ·
            if self.enable_per:
                experiences, indices, weights = self.sub_buffers[cluster_type].sample(batch_size)
                importance_weights = weights
            else:
                experiences = random.sample(list(self.sub_buffers[cluster_type]), batch_size)
                indices = None
                importance_weights = None

            # ğŸ¯ æ•°æ®è½¬æ¢å’ŒéªŒè¯
            states = []
            actions = []
            rewards = []
            next_states = []
            dones = []

            for exp in experiences:
                # æ•°æ®éªŒè¯
                if (not np.any(np.isnan(exp.state)) and not np.any(np.isnan(exp.next_state)) and
                    not np.any(np.isnan(exp.action)) and not np.isnan(exp.reward)):

                    # ğŸ¯ ç¡®ä¿ç»´åº¦æ­£ç¡®
                    state = exp.state if len(exp.state) == state_dim else np.resize(exp.state, state_dim)
                    next_state = exp.next_state if len(exp.next_state) == state_dim else np.resize(exp.next_state, state_dim)
                    action = exp.action if len(exp.action) == action_dim else np.resize(exp.action, action_dim)

                    states.append(state)
                    actions.append(action)
                    rewards.append(exp.reward)
                    next_states.append(next_state)
                    dones.append(float(exp.done))

            # å¦‚æœè¿‡æ»¤åæ•°æ®ä¸è¶³ï¼Œç”¨é»˜è®¤æ•°æ®è¡¥é½
            while len(states) < batch_size:
                states.append(np.zeros(state_dim, dtype=np.float32))
                actions.append(np.zeros(action_dim, dtype=np.float32))
                rewards.append(0.0)
                next_states.append(np.zeros(state_dim, dtype=np.float32))
                dones.append(0.0)

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            states = np.array(states[:batch_size], dtype=np.float32)
            actions = np.array(actions[:batch_size], dtype=np.float32)
            rewards = np.array(rewards[:batch_size], dtype=np.float32).reshape(-1, 1)
            next_states = np.array(next_states[:batch_size], dtype=np.float32)
            dones = np.array(dones[:batch_size], dtype=np.float32).reshape(-1, 1)

            # ğŸ¯ æ›´æ–°é‡‡æ ·ç»Ÿè®¡
            self.sampling_stats['sub_samples'][cluster_type] += 1
            self.sampling_stats['last_sample_time'] = time.time()

            return states, actions, rewards, next_states, dones, importance_weights

        except Exception as e:
            print(f"âš ï¸ å­æ§åˆ¶å™¨é‡‡æ ·é”™è¯¯ ({cluster_type}): {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤æ•°æ®
            state_dims = {'FPGA': 6, 'FOG_GPU': 8, 'CLOUD': 6}
            action_dims = {'FPGA': 2, 'FOG_GPU': 3, 'CLOUD': 2}
            state_dim = state_dims.get(cluster_type, 6)
            action_dim = action_dims.get(cluster_type, 2)

            dummy_state = np.zeros((batch_size, state_dim), dtype=np.float32)
            dummy_action = np.zeros((batch_size, action_dim), dtype=np.float32)
            dummy_reward = np.zeros((batch_size, 1), dtype=np.float32)
            dummy_next_state = np.zeros((batch_size, state_dim), dtype=np.float32)
            dummy_done = np.zeros((batch_size, 1), dtype=np.float32)
            return dummy_state, dummy_action, dummy_reward, dummy_next_state, dummy_done, None

    def update_priorities(self, experience_type: str, indices: np.ndarray,
                         priorities: np.ndarray, cluster_type: str = None):
        """ğŸ¯ æ›´æ–°ç»éªŒä¼˜å…ˆçº§"""
        try:
            if not self.enable_per:
                return

            if experience_type == 'meta':
                self.meta_buffer.update_priorities(indices, priorities)
            elif experience_type == 'sub' and cluster_type in self.sub_buffers:
                self.sub_buffers[cluster_type].update_priorities(indices, priorities)

        except Exception as e:
            print(f"âš ï¸ ä¼˜å…ˆçº§æ›´æ–°é”™è¯¯: {e}")

    def get_buffer_status(self) -> Dict:
        """ğŸ¯ è·å–ç¼“å†²åŒºçŠ¶æ€æ‘˜è¦"""
        try:
            # è®¡ç®—è´¨é‡ç»Ÿè®¡
            meta_avg_quality = (np.mean(list(self.quality_monitor['meta_quality_history']))
                              if self.quality_monitor['meta_quality_history'] else 0)

            sub_avg_qualities = {}
            for cluster_type, quality_history in self.quality_monitor['sub_quality_history'].items():
                sub_avg_qualities[cluster_type] = (np.mean(list(quality_history))
                                                 if quality_history else 0)

            status = {
                'buffer_sizes': {
                    'meta': len(self.meta_buffer),
                    **{cluster: len(buffer) for cluster, buffer in self.sub_buffers.items()}
                },
                'capacity_utilization': {
                    'meta': len(self.meta_buffer) / (self.capacity // 2),
                    **{cluster: len(buffer) / (self.capacity // 6)
                       for cluster, buffer in self.sub_buffers.items()}
                },
                'quality_stats': {
                    'total_experiences': self.quality_monitor['total_experiences'],
                    'filtered_experiences': self.quality_monitor['filtered_experiences'],
                    'filter_rate': (self.quality_monitor['filtered_experiences'] /
                                  max(1, self.quality_monitor['total_experiences'])),
                    'meta_avg_quality': meta_avg_quality,
                    'sub_avg_qualities': sub_avg_qualities
                },
                'sampling_stats': self.sampling_stats.copy(),
                'configuration': {
                    'enable_per': self.enable_per,
                    'quality_threshold': self.quality_threshold,
                    'balance_sampling': self.balance_sampling
                }
            }

            return status

        except Exception as e:
            print(f"âš ï¸ ç¼“å†²åŒºçŠ¶æ€è·å–é”™è¯¯: {e}")
            return {'error': str(e)}

    def __len__(self):
        """è¿”å›æ€»ç»éªŒæ•°é‡"""
        try:
            total = len(self.meta_buffer)
            for buffer in self.sub_buffers.values():
                total += len(buffer)
            return total
        except Exception as e:
            print(f"âš ï¸ é•¿åº¦è®¡ç®—é”™è¯¯: {e}")
            return 0

    def clear(self):
        """ğŸ¯ æ™ºèƒ½æ¸…ç©ºç¼“å†²åŒº"""
        try:
            # ä¿å­˜é‡è¦ç»Ÿè®¡ä¿¡æ¯
            total_before = len(self)

            # æ¸…ç©ºç¼“å†²åŒº
            if hasattr(self.meta_buffer, 'clear'):
                self.meta_buffer.clear()
            else:
                self.meta_buffer = (PrioritizedExperienceReplay(self.capacity // 2)
                                  if self.enable_per else deque(maxlen=self.capacity // 2))

            for cluster_type in self.sub_buffers:
                if hasattr(self.sub_buffers[cluster_type], 'clear'):
                    self.sub_buffers[cluster_type].clear()
                else:
                    sub_capacity = self.capacity // 6
                    self.sub_buffers[cluster_type] = (PrioritizedExperienceReplay(sub_capacity)
                                                    if self.enable_per else deque(maxlen=sub_capacity))

            # é‡ç½®éƒ¨åˆ†ç»Ÿè®¡ï¼ˆä¿ç•™é…ç½®ï¼‰
            self.sampling_stats.update({
                'meta_samples': 0,
                'sub_samples': {cluster: 0 for cluster in ['FPGA', 'FOG_GPU', 'CLOUD']},
                'quality_filtered': 0,
                'last_sample_time': time.time()
            })

            print(f"ğŸ”„ ç¼“å†²åŒºå·²æ¸…ç©º ({total_before} ä¸ªç»éªŒ)")

        except Exception as e:
            print(f"âš ï¸ ç¼“å†²åŒºæ¸…ç©ºé”™è¯¯: {e}")


# ğŸ¯ ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸå§‹ç±»å
HierarchicalReplayBuffer = StabilizedHierarchicalReplayBuffer


# ğŸ§ª å¢å¼ºçš„æµ‹è¯•å‡½æ•°
def test_stabilized_replay_buffer():
    """æµ‹è¯•ç¨³å®šåŒ–å›æ”¾ç¼“å†²åŒº"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•StabilizedHierarchicalReplayBuffer...")

    try:
        # åˆ›å»ºç¨³å®šåŒ–å›æ”¾ç¼“å†²åŒº
        buffer = StabilizedHierarchicalReplayBuffer(
            capacity=1000,
            enable_per=True,
            quality_threshold=0.1,
            balance_sampling=True
        )

        # æµ‹è¯•1: åŸºæœ¬ç»éªŒæ·»åŠ 
        print("\nğŸ“ æµ‹è¯•1: åŸºæœ¬ç»éªŒæ·»åŠ æµ‹è¯•")

        # æ·»åŠ å…ƒæ§åˆ¶å™¨ç»éªŒ
        for i in range(50):
            state = np.random.random(15).astype(np.float32)
            action = np.random.random(3).astype(np.float32)
            action = action / np.sum(action)  # å½’ä¸€åŒ–ä¸ºæ¦‚ç‡åˆ†å¸ƒ
            reward = np.random.uniform(-10, 10)
            next_state = np.random.random(15).astype(np.float32)
            done = np.random.choice([True, False])

            success = buffer.push_meta(state, action, reward, next_state, done)
            if i == 0:
                print(f"âœ… é¦–æ¬¡å…ƒæ§åˆ¶å™¨ç»éªŒæ·»åŠ : {'æˆåŠŸ' if success else 'å¤±è´¥'}")

        # æ·»åŠ å­æ§åˆ¶å™¨ç»éªŒ
        for cluster_type in ['FPGA', 'FOG_GPU', 'CLOUD']:
            state_dims = {'FPGA': 6, 'FOG_GPU': 8, 'CLOUD': 6}
            action_dims = {'FPGA': 2, 'FOG_GPU': 3, 'CLOUD': 2}

            for i in range(30):
                state = np.random.random(state_dims[cluster_type]).astype(np.float32)
                action = np.random.random(action_dims[cluster_type]).astype(np.float32)
                reward = np.random.uniform(-5, 15)
                next_state = np.random.random(state_dims[cluster_type]).astype(np.float32)
                done = np.random.choice([True, False])

                success = buffer.push_sub(cluster_type, state, action, reward, next_state, done)
                if i == 0:
                    print(f"âœ… {cluster_type}é¦–æ¬¡ç»éªŒæ·»åŠ : {'æˆåŠŸ' if success else 'å¤±è´¥'}")

        print(f"æ€»ç»éªŒæ•°: {len(buffer)}")

        # æµ‹è¯•2: é‡‡æ ·åŠŸèƒ½
        print("\nğŸ“ æµ‹è¯•2: é‡‡æ ·åŠŸèƒ½æµ‹è¯•")

        # å…ƒæ§åˆ¶å™¨é‡‡æ ·
        if buffer.can_sample(8):
            states, actions, rewards, next_states, dones, weights = buffer.sample_meta(8)
            print(f"âœ… å…ƒæ§åˆ¶å™¨é‡‡æ ·: {states.shape}, æƒé‡: {'æœ‰' if weights is not None else 'æ— '}")

        # å­æ§åˆ¶å™¨é‡‡æ ·
        for cluster_type in ['FPGA', 'FOG_GPU', 'CLOUD']:
            if buffer.can_sample_sub(cluster_type, 4):
                states, actions, rewards, next_states, dones, weights = buffer.sample_sub(cluster_type, 4)
                print(f"âœ… {cluster_type}é‡‡æ ·: {states.shape}, {actions.shape}")

        # æµ‹è¯•3: ç¼“å†²åŒºçŠ¶æ€
        print("\nğŸ“ æµ‹è¯•3: ç¼“å†²åŒºçŠ¶æ€æµ‹è¯•")
        status = buffer.get_buffer_status()
        print(f"âœ… ç¼“å†²åŒºçŠ¶æ€:")
        print(f"  - å…ƒæ§åˆ¶å™¨å¤§å°: {status['buffer_sizes']['meta']}")
        print(f"  - å¹³å‡è´¨é‡: {status['quality_stats']['meta_avg_quality']:.3f}")
        print(f"  - è¿‡æ»¤ç‡: {status['quality_stats']['filter_rate']:.1%}")

        # æµ‹è¯•4: è´¨é‡è¿‡æ»¤
        print("\nğŸ“ æµ‹è¯•4: è´¨é‡è¿‡æ»¤æµ‹è¯•")

        # æ·»åŠ ä½è´¨é‡ç»éªŒï¼ˆåŒ…å«NaNï¼‰
        bad_state = np.full(15, np.nan, dtype=np.float32)
        bad_action = np.random.random(3).astype(np.float32)
        success = buffer.push_meta(bad_state, bad_action, 5.0, np.random.random(15).astype(np.float32), False)
        print(f"âœ… ä½è´¨é‡ç»éªŒè¿‡æ»¤: {'å·²è¿‡æ»¤' if not success else 'æœªè¿‡æ»¤'}")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼StabilizedHierarchicalReplayBufferå·¥ä½œæ­£å¸¸")
        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    success = test_stabilized_replay_buffer()
    if success:
        print("\nâœ… Stabilized Hierarchical Replay Buffer ready for production!")
        print("ğŸ¯ ä¸»è¦ä¼˜åŒ–:")
        print("  - ä¼˜å…ˆçº§ç»éªŒå›æ”¾: é‡è¦ç»éªŒä¼˜å…ˆå­¦ä¹ ")
        print("  - ç»éªŒè´¨é‡è¿‡æ»¤: è‡ªåŠ¨è¿‡æ»¤æ— æ•ˆç»éªŒ")
        print("  - ç¨³å®šåŒ–é‡‡æ ·: ç¡®ä¿è®­ç»ƒæ•°æ®è´¨é‡")
        print("  - å†…å­˜ä¼˜åŒ–ç®¡ç†: é«˜æ•ˆçš„æ•°æ®å­˜å‚¨")
        print("  - å®æ—¶ç›‘æ§ç»Ÿè®¡: ç¼“å†²åŒºçŠ¶æ€è·Ÿè¸ª")
    else:
        print("\nâŒ Stabilized Hierarchical Replay Buffer needs debugging!")